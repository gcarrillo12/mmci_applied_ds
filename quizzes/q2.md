# Applied Data Science, Block 2

### Reading Questions

*from [Khera et al., 2021](https://jamanetwork.com/journals/jamacardiology/fullarticle/2777055)*

1. The authors develop machine learning models to predict death after acute myocardial infarction. The shape of the dataset used to develop these models may be described as:
  - N &#8811; P, i.e. many more patients than features
  - N &#8810; P, i.e. many more features than patients
  - N &asymp; P, i.e. approximately as many patients as features
2. The machine learning models showed improved calibration compared to logistic regression. In this setting, which of the following best describes good calibration?
  - There is high overlap between the features determined to be important by the model and the features clinicians believe are important.
  - Mortality risk predicted by the model is a good estimate of true mortality risk.
  - Calibration is another term for discrimination performance. In other words, models with high area under the sensitivity/specificity curve are well calibrated.
3. Which of the following best describes the authors' final strategy for imputing missing categorical variables?
  - A new category was created for these values. In other words, "missing" was viewed as a value of the variable.
  - Missing values were predicted based on the values of the other predictors for that patient.
  - Missing values were assigned to the category most commonly observed in the dataset.
  - Missing values were assigned to the average value for that variable.
4. Which of the following models do *the authors* claim is interpretable?
  - The LASSO model, because it is a generalized linear model
  - The neural network, because new approaches have been developed to understand the importance of individual features
  - The XGBoost model, because it is based on a collection of decision trees
  - The meta-classifier, because its decisions are based on all of the previous 3 models
6. Q5

*from [Engelhard et al., 2021](https://jamanetwork.com/journals/jamacardiology/article-abstract/2777054)*

6. Q6
7. Q7
8. Q8
9. Q9
10. Q10

### Discussion Questions

1. Khera et al. repeatedly emphasize the importance of interpretability, and we have discussed multiple perspectives on interpretability in class. Do you believe model interpretability is important? Why or why not? And regardless, do you believe that models commonly claimed to be interpretable truly are?
2. 
3. DQ3
